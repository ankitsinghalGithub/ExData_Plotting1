library('rJava'')
fileUrl <-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx"
download.file(fileUrl,destfile="ngp.xlsx")
download.file(fileUrl,destfile="/ngp.xlsx")
download.file(fileUrl,destfile="/ngp.xlsx", method="curl")
setInternet2(use = TRUE)
download.file(fileUrl,destfile="/ngp.xlsx")
download.file(fileUrl,destfile="ngp.xlsx")
library(openxlsx)
colIndex <-7:15
rowIndex <- 18-23
dat <- <- read.xlsx("ngp.xlsx", sheet=1, cols=colIndex, rows=rowIndex)
dat <- read.xlsx("ngp.xlsx", sheet=1, cols=colIndex, rows=rowIndex)
dat
download.file(fileUrl,destfile="ngp.xlsx" mode="wb")
dat <- read.xlsx("ngp.xlsx", sheet=1, header=True)
dat <- read.xlsx("ngp.xlsx", sheet=1)
dat <- read.xlsx("ngp.xlsx", sheet=1, header=TRUE)
list.files()
dat <- read.xlsx("./Data/ngp.xlsx", sheet=1, header=TRUE)
dat <- read.xlsx("./Data/ngp.xlsx", sheet=1)
getwd()
dat <- read.xlsx("/Data/ngp.xlsx", sheet=1)
dat <- read.xlsx("/data/ngp.xlsx", sheet=1)
dat <- read.xlsx("ngp.xlsx", sheet=1)
download.file(fileUrl,destfile="ngp1.xlsx" mode="wb")
fileUrl
download.file(fileUrl,destfile="ngp1.xlsx", mode="wb")
dat1 <- read.xlsx("ngp.xlsx", sheet=1)
dat1 <- read.xlsx("ngp1.xlsx", sheet=1)
data1
dat1[1:6,]
dat <- read.xlsx("ngp1.xlsx", sheet=1, cols=colIndex, rows=rowIndex)
dat[1:6,]
cols
colIndex
rowIndexIndex
rowIndex
rowIndex <- 18:23
rowIndex
dat <- read.xlsx("ngp1.xlsx", sheet=1, cols=colIndex, rows=rowIndex)
sum(dat$Zip*dat$Ext,na.rm=T)
library(XML)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
download.file(fileUrl,destfile="ngp1.xml")
doc <-xmlTreeParse("ngp1.xml", UseInternal=TRUE)
doc <-xmlTreeParse("ngp1.xml")
rootNode <-xmlRoot(doc)
xmlName(rootNode)
names(rootNode)
xmlSApply(rootNode,xmlValue)
pin <- xmlSApply(rootNode,"//zipcode", xmlValue)
xmlSApply(rootNode,"//zipcode", xmlValue)
pin <- xpathSApply(rootNode,"//zipcode", xmlValue)
xpathSApply(rootNode,"//zipcode", xmlValue)
xpathSApply(doc,"//zipcode", xmlValue)
xmlSApply(rootNode,"/zipcode", xmlValue)
xmlSApply(rootNode[1],"//zipcode", xmlValue)
xpathSApply(rootNode,"//zipcode", xmlValue)
https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml
xpathSApply(rootNode,"//zipcode",xmlValue)
a=xpathSApply(rootNode,"//zipcode",xmlValue)
a=xpathSApply(rootNode,"///zipcode",xmlValue)
a <-xmlName(rootNode)
a
b <- xmlName(a)
b <- xmlName(//rootNode)
xmlValue(doc["//zipcode"])
xmlValue(doc[["//zipcode"]])
doc <-xmlTreeParse("ngp1.xml", UseInternal=TRUE)
doc <-xmlTreeParse("ngp1.xml", UseInternalNodes=TRUE)
fileUrl
doc <-xmlTreeParse(fileUrl, UseInternal=TRUE)
doc <-xmlTreeParse("ngp1.xml", useInternal=TRUE)
rootNode <-xmlRoot(doc)
a=xpathSApply(rootNode,"///zipcode",xmlValue)
a
a[1:5,]
a[1:5]
b <- a==21231
b
c <-a[b]
c
length(c)
fileUrl <-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(fileUrl,destfile="abc.csv")
list.files()
a <-fread("abc.csv")
library(data.table)
install.package(data.table)
install.packages(data.table)
install.packages("data.table")
library(data.table)
DT <-fread("abc.csv")
DT <-fread("abc.csv", sep=",")
DT <-fread("abc.csv", sep=',')
big_df <- data.frame(norm(1e6), norm(1e6))
big_df <- data.frame(x=norm(1e6), y=norm(1e6))
big_df <- data.frame(x=rnorm(1e6), y=rnorm(1e6))
file <-tempfile
file <-tempfile()
write.table(big_df, file=file, row.names=FALSE, col.names=TRUE, sep=',', quote=FALSE)
file <-abc.csv
file <-"abc.csv"
file
write.table(big_df, file=file, row.names=FALSE, col.names=TRUE, sep=',', quote=FALSE)
system.time(fread(file))
system.time(read.table(file,header=TRUE, sep=','))
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
DT <- fread(file)
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
DT <- file
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
DT <- big_df
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
DT[,mean(pwgtp15),by=SEX]
system.time(DT[,mean(pwgtp15),by=SEX])
system.time(mean(DT$pwgtp15,by=DT$SEX))
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
system.time(mean(DT[DT$SEX==2,]$pwgtp15))
system.time(mean(DT[DT$SEX==1,]$pwgtp15))
system.time(rowMeans(DT)[DT$SEX==1])
system.time(rowMeans(DT)[DT$SEX==2])
system.time(DT[,mean(pwgtp15),by=SEX])
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
system.time(DT[,mean(pwgtp15),by=SEX])
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
system.time(rowMeans(DT)[DT$SEX==1])
rowMeans(DT)[DT$SEX==1]
sapply(split(DT$pwgtp15,DT$SEX),mean)
tapply(DT$pwgtp15,DT$SEX,mean)
q()
library(httr)
myapp <- oauth_app("github",key="a5f2deff7c78b8ce19c7",secret = "1d1ace8d0bc3fce9f072831373b65181d059ada3")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
library(httr)
myapp <- oauth_app("github",key="a5f2deff7c78b8ce19c7",secret = "1d1ace8d0bc3fce9f072831373b65181d059ada3")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- with_config(gtoken, GET("https://api.github.com/users/jtleek/repos"))
stop_for_status(req)
json1 <-content(req)
json2 <- jsonLite::fromJSON(toJSON(json1))
install.package('jsonLite')
install.packages('jsonLite')
install.packages('jsonlite')
library('jsonlite')
library(jsonlite)
getwd()
library(jsonlite)
library(/R/jsonlite)
library("./R/jsonlite")
library("jsonlite")
json2 <- jsonLite::fromJSON(toJSON(json1))
json2 <- jsonlite::fromJSON(toJSON(json1))
json2 <- jsonlite::fromJSON(json1)
json2 <- jsonlite::fromJSON(toJSON(json1))
library("jsonlite")
install.package('jsonlite')
install.package(jsonlite)
install.packages(jsonlite)
install.packages(jsonlite)
install.packages('jsonlite')
library(jsonlite)
install.package(jsonlite)
install.package(rjson)
json2 <- jsonlite::fromJSON(toJSON(json1))
json2 <- jsonlite::fromjson(tojson(json1))
install.packages("jsonlite", repos="http://cran.r-project.org")
library(jsonlite)
library('jsonlite')
myjson <- toJSON(json1, pretty=TRUE)
library('rjson')
install.packages("rjson", repos="http://cran.r-project.org")
library('rjson')
myjson <- toJSON(json1, pretty=TRUE)
myjson <- toJSON(json1)
json2 <- jsonlite::fromjson(tojson(json1))
json2 <- jsonlite::fromJSON(toJSON(json1))
json2[1,1:4]
head(json2)
json2
json1 <-content(req)
json2 <- jsonlite::fromJSON(toJSON(json1))
json2
json1 <-content(req)
json1
req
library(httr)
q()
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github",key ="a5f2deff7c78b8ce19c7", secret="1d1ace8d0bc3fce9f072831373b65181d059ada3")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
stop_for_status(req)
content(req)
library(httpuv)
library(httpuv)
library(httr)
library(jsonlite)
oauth_endpoints("github")
myapp <- oauth_app("github",key ="a5f2deff7c78b8ce19c7", secret="1d1ace8d0bc3fce9f072831373b65181d059ada3")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
req <- GET("https://api.github.com/users/jtleek/repos", config(token = github_token))
stop_for_status(req)
content(req)
##  to write a pair of functions that cache the inverse of a matrix
## makeCacheMatrix: This function creates a special "matrix" object
## that can cache its inverse
makeCacheMatrix <- function(x = matrix()) {
## inv-inverse Matrix; m<-matrix;
inv <- NULL
set <- function(m) {
x <<- m
inv <<- NULL
}
get <- function() x
setInverse <- function(inverse) inv <<- inverse
getInverse <- function() inv
list(set = set, get = get,
setInverse = setInverse,
getmean = getInverse)
}
## cacheSolve function computes the inverse of the special "matrix"
## returned by makeCacheMatrix above. If the inverse has already been
## calculated (and the matrix has not changed), then the cachesolve
## should retrieve the inverse from the cache.
cacheSolve <- function(x, ...) {
inv <- x$getInverse()
if(!is.null(inv)) {
message("getting cached data")
return(inv)
}
data <- x$get()
inv <- solve(data, ...)
x$setInverse(inv)
inv
}
m<-matrix(1:4, nrow=2, ncol=2)
m
cacheSolve(m)
makeCacheMatrix()
cacheSolve(m)
##  to write a pair of functions that cache the inverse of a matrix
## makeCacheMatrix: This function creates a special "matrix" object
## that can cache its inverse
makeCacheMatrix <- function(x = matrix()) {
## inv-inverse Matrix; m<-matrix;
inv <- NULL
set <- function(m) {
x <<- m
inv <<- NULL
}
get <- function() x
setInverse <- function(inverse) inv <<- inverse
getInverse <- function() inv
list(set = set, get = get,
setInverse = setInverse,
getInverse = getInverse)
}
## cacheSolve function computes the inverse of the special "matrix"
## returned by makeCacheMatrix above. If the inverse has already been
## calculated (and the matrix has not changed), then the cachesolve
## should retrieve the inverse from the cache.
cacheSolve <- function(x, ...) {
inv <- x$getInverse()
if(!is.null(inv)) {
message("getting cached data")
return(inv)
}
data <- x$get()
inv <- solve(data, ...)
x$setInverse(inv)
inv
}
makeCacheMatrix()
cacheSolve(m)
makeCacheMatrix(m)
m
a<-makeCacheMatrix()
cacheSolve(a)
cacheSolve <- function(x, ...) {
inv <- x$getInverse()
if(!is.null(inv)) {
message("getting cached data")
return(inv)
}
data <- x$get()
inv <- solve(data, ...)
x$setInverse(inv)
data
}
cacheSolve(a)
a<-makeCacheMatrix(m)
m
cacheSolve(a)
cacheSolve <- function(x) {
inv <- x$getInverse()
if(!is.null(inv)) {
message("getting cached data")
return(inv)
}
data <- x$get()
inv <- solve(data)
x$setInverse(inv)
inv
}
cacheSolve(a)
cacheSolve(a)
makeCacheMatrix(m)
m
b<-makeCacheMatrix(m)
cacheSolve(b)
cacheSolve(b)
q()
library(swirl)
swirl()
5 + 7
x <- 5+7
x
y <- x-3
y
z <- c(1.1, 9, 3.14)
?c
z
c(z, 555, z)
z *2 +100
my_sqrt <- sqrt(z-1)
my_sqrt
my_div <- z/my_sqrt
my_div
c(1,2,3,4) + c(0,10)
c(1,2,3,4)+c(0,10,100)
z *2 +1000
my_div
getwd()
ls()
x<-9
ls()
list.files()
?list.files
arg()
args()
args(list.fles)
args(list.files())
args(list.files)
old.dir <- getwd()
dir.create("testdir")
setwd("testdir")
file.create("mytest.R")
list.files()
file.exists("mytest.R")
file.info("mytest.R")
file.rename("mytest.R", "mytest2.R")
file.copy("mytest2.R", "mytest3.R")
file.path("mytest3.R")
file.path('folder', 'folder2')
file.path('folder1', 'folder2')
info()
?dir.create
dir.create("testdir2", file.path("testdir2/testdir3"), recursive=true)
dir.create("testdir2", file.path("testdir2/testdir3"), recursive=True)
dir.create("testdir2", file.path("testdir2/testdir3"), recursive=TRUE)
dir.create(file.path("testdir2","testdir3"), recursive=TRUE)
unlink("testdir2")
unlink("testdir2", recursive=TRUE)
getwd()
setwd(old.dir)
unlink("testdir")
unlink("testdir", recursive=TRUE)
1:20
pi:10
15:1
?:
?'':
'
?
':'
?':'
seq(1,20)
seq(0,10,by=0.5)
my_seq=seq(5,10, length=30)
my_seq<-seq(5,10, length=30)
length(my_seq)
1:length(my_seq)
seq(along.with = my_seq)
seq_along(my_seq)
rep(0, times =40)
rep(c(0,1,2), times =10)
rep(c(0,1,2), each=10)
num_vect<-c(0.5,55,-10,6)
tf <-num_vect<1
tf
num_vect >=6
my_char<-c("My", "name", "is")
my_char
paste(my_char, collapse = " ")
my_name <- c(my_char, "Ankit Singhal")
my_name
paste(my_name, collapse=" ")
paste("Hello", "World!", sep =" ")
paste("Hello", "world!", sep =" ")
paste("X","Y","Z", sep=" ")
paste(1:3, c("X","Y","Z"), sep=""))
paste(1:3, c("X","Y","Z"), sep="")
paste(LETTERS, 1:4, sep ="-")
x<-c(44, NA, 5, NA)
x*3
y <- rnorm(1000)
z <- rep(NA, 1000)
my_data <- sample(c(y,z),100)
my_na<-is.na(my_data)
my_na
my_data == NA
sum(my_na)
my_data
0/0
Inf-Inf
swirl()
q()
source(run_analysis.R)
getwd()
setwd("getCleanDataProject")
setwd("/getCleanDataProject")
setwd("./getCleanDataProject")
ls
ls()
setwd("\getCleanDataProject")
setwd("/getCleanDataProject")
setwd("getCleanDataProject")
setwd("./getCleanDataProject")
setwd("./getCleanDataProject")
library (swirl)
swirl()
mydf <- read.csv(path2csv, stringsAsFactors = FALSE)
dim()
dim(mydf)
head(mydf)
library(dplyr)
type packageVersion("dplyr")
packageVersion("dplyr")
cran<- tbl_df(mtdf)
cran<- tbl_df(mydf)
rm("mrdf")
rm("mydf")
cran
?select()
?select
select(cran, ip_id, package, country)
5:20
select(cran, r_arch:country)
select(cran, country:r_arch)
cran
select(cran, -time)
-5:20
5:20
-(5:20)
select(cran,-(x:ip_id))
select(cran,-(x:size))
select(cran,-(X:size))
filter(cran, package=="swirl")
filter(cran, r_version=="3.1.1", country=="US")
?Comparison
filter(cran, r_version=="3.1.1", country=="IN")
filter(cran, r_version=="3.0.2", country=="IN")
filter(cran, r_version<="3.0.2", country=="IN")
filter(cran, country == " US", country=="IN")
filter(cran, country == " US" | country=="IN")
filter(cran, country == "US" | country=="IN")
filter(cran, size>100500,r_os=="linux-gnu")
is.na(c(3,5,NA,10))
!is.na(c(3,5,NA,10))
filter(cran, !is.na(r_version))
cran2<-select(cran,size:ip_id)
arrange(cran2, ip_id)
desc(cran2, ip_id)
arrange(cran2, desc(ip_id))
arrange(cran2, package, ip_id)
arrange(cran2, country, desc(r_version), ip_id)
cran3<-select(cran, ip_id,package,size)
cran3
mutate(cran3, size_mb=size/ 2^20)
mutate(cran3, size_mb=size/ 2^20, size_gb=size_mb/2^10)
mutate(cran3, correct_size=size-1000)
mutate(cran3, correct_size=size+1000)
summary(cran, avg=mean(size))
summarize(cran, avg=mean(size))
summarize(cran, avg_bytes=mean(size))
swirl()
library (swirl)
swirl()
swirl()
q()
library(dplyr)
library(tdyr)
library(tidyr)
df <- data.frame(x = c("a", "b"), y = c(3, 4), z = c(5, 6))
df
df %>% spread(x, y) %>% gather(x, y, a:b, na.rm = TRUE)
df <- data.frame(x = c("a", "b"), y = c(3, 4), z = c(5, 6))
df %>% spread(x, y)
df <- data.frame(x = c("a", "b"), y = c(3, 4), z = c(5, 6))
df
df %>% spread(x)
df %>% spread(x,z)
help.search("date")
q()
setwd("~/datasciencetestcourseraRepo/exploratoryData/ExData_Plotting1")
source('~/datasciencetestcourseraRepo/exploratoryData/ExData_Plotting1/plot4.R')
